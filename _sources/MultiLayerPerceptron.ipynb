{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN1k9LEQTc7+xPJFEzSwMRD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":19,"metadata":{"id":"X_-ncCkVljrM","executionInfo":{"status":"ok","timestamp":1684309688582,"user_tz":-420,"elapsed":1857,"user":{"displayName":"20-055 WAHYU ARIL SAPUTRA","userId":"15073584488611319877"}}},"outputs":[],"source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np"]},{"cell_type":"code","source":["class MLP:\n","    def __init__(self, input_size, hidden_size, output_size):\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        \n","        # Initialize weights randomly for the hidden layer and output\n","        self.weights1 = np.random.randn(self.input_size, self.hidden_size)\n","        self.weights2 = np.random.randn(self.hidden_size, self.output_size)\n","        self.bias1 = np.zeros((1, self.hidden_size))\n","        self.bias2 = np.zeros((1, self.output_size))\n","\n","    def sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    def sigmoid_derivative(self, x):\n","        return x * (1 - x)\n","\n","    def feedforward(self, X):\n","        # Calculate hidden layer\n","        self.hidden_layer = self.sigmoid(np.dot(X, self.weights1) + self.bias1)\n","\n","        # Calculate output layer\n","        self.output_layer = self.sigmoid(\n","            np.dot(self.hidden_layer, self.weights2) + self.bias2\n","        )\n","\n","        return self.output_layer\n","\n","    def backpropagation(self, X, y, output):\n","        # Feed forward\n","        self.feedforward(X)\n","        \n","        # Menghitung error pada output layer\n","        output_error = y - output\n","        \n","        # Menghitung gradien pada output layer\n","        output_gradient = output_error * self.sigmoid_derivative(output)\n","        \n","        # Menghitung error pada layer tersembunyi\n","        hidden_error = np.dot(output_gradient, self.weights2.T)\n","        \n","        # Menghitung gradien pada layer tersembunyi\n","        hidden_gradient = hidden_error * self.sigmoid_derivative(self.hidden_layer)\n","        \n","        # Memperbarui bobot pada layer tersembunyi dan output\n","        self.weights2 += np.dot(self.hidden_layer.T, output_gradient) * learning_rate\n","        self.weights1 += np.dot(X.T, hidden_gradient) * learning_rate\n","\n","    def train(self, X, y, num_epochs):\n","        for epoch in range(num_epochs):\n","            # Forward pass\n","            output = self.feedforward(X)\n","\n","            # Backward pass\n","            self.backpropagation(X, y, output)\n","\n","            # Calculate loss\n","            loss = np.mean(np.square(y - output))\n","            if epoch % 100 == 0:\n","                print(\"Epoch %d Loss: %.4f\" % (epoch, loss))\n","\n","    # def trainSGD(self, X, y, learning_rate, epochs):\n","    #     for epoch in range(epochs):\n","    #         for i in range(len(X)):\n","    #             x_i = X[i]\n","    #             y_i = y[i]\n","    #             mlp.backpropagation(x_i.reshape(1, -1), y_i.reshape(1, -1), learning_rate)\n","            \n","    #         # Cetak bobot setelah setiap epoch\n","    #         print(f\"Epoch {epoch+1}:\")\n","    #         mlp.show_weights()\n","    #         print(\"--------------------\")\n","\n","    def predict(self, X):\n","        return np.round(self.feedforward(X))\n","    \n","    def show_architecture(self):\n","        print(\"MLP Architecture:\")\n","        print(f\"Input layer: {self.input_size} neurons\")\n","        print(f\"Hidden layer: {self.hidden_size} neurons\")\n","        print(f\"Output layer: {self.output_size} neurons\")\n","    \n","    def show_weights(self,epoch):\n","        print(f\"Epoch ke: {epoch+1}\")\n","        print(\"Bobot MLP:\")\n","        print(\"W1:\", self.weights1)\n","        print(\"W2:\", self.weights2)"],"metadata":{"id":"IodwC2MrlpTr","executionInfo":{"status":"ok","timestamp":1684312263657,"user_tz":-420,"elapsed":585,"user":{"displayName":"20-055 WAHYU ARIL SAPUTRA","userId":"15073584488611319877"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# # 2 input 4 hidden dan 1 output\n","# mlp = MLP(2, 4, 1)\n","# X = np.array([[0, 1]])  # Input\n","# y = np.array([[1]])     # Target output\n","# output = 1     # Learning rate\n","# # output = mlp.feedforward(X)\n","# mlp.backpropagation(X, y,output)\n","# # print(\"Output:\", output)\n","# print(\"Updated weights:\")\n","# print(\"W1:\", mlp.weights1)\n","# print(\"W2:\", mlp.weights2)"],"metadata":{"id":"wveqrLXJnrcc","executionInfo":{"status":"ok","timestamp":1684311425071,"user_tz":-420,"elapsed":352,"user":{"displayName":"20-055 WAHYU ARIL SAPUTRA","userId":"15073584488611319877"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["## Menggunakan Dataset Iris"],"metadata":{"id":"DHsDs_9Ytvru"}},{"cell_type":"code","source":["iris = load_iris()\n","X = iris.data\n","y = iris.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Konversi label menjadi one-hot encoding\n","num_classes = len(np.unique(y))\n","y_train_encoded = np.eye(num_classes)[y_train]\n","\n","# Inisialisasi dan melatih MLP\n","mlp = MLP(input_size=X_train.shape[1], hidden_size=4, output_size=num_classes)\n","learning_rate = 0.1\n","epochs = 10\n","# mlp.trainSGD(mlp,X_train, y_train_encoded, learning_rate, epochs)\n","\n","for epoch in range(epochs):\n","    mlp.backpropagation(X_train, y_train_encoded, learning_rate)\n","    mlp.show_weights(epoch)\n","    print(\"--------------------\")\n","\n","# Evaluasi performa model pada data uji\n","y_pred = np.argmax(mlp.feedforward(X_test), axis=1)\n","accuracy = np.mean(y_pred == y_test)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zBvCnRVp8_-","executionInfo":{"status":"ok","timestamp":1684312272623,"user_tz":-420,"elapsed":454,"user":{"displayName":"20-055 WAHYU ARIL SAPUTRA","userId":"15073584488611319877"}},"outputId":"e162d8c7-7996-4125-c9ea-a5e9a80d379c"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch ke: 1\n","Bobot MLP:\n","W1: [[-0.21938659  0.25884068  0.43629488  0.88466793]\n"," [ 0.34778726  0.23416242 -0.14807368 -1.79906437]\n"," [-0.76594992  1.09195099 -0.24026831 -0.76992225]\n"," [-2.60366939  1.27755224  2.10886911 -1.38988557]]\n","W2: [[ 0.45233559  1.09666929 -0.41894741]\n"," [-0.76996743  1.11663974  0.11955283]\n"," [-0.08237649 -0.25240515  0.60943081]\n"," [-0.93860573  0.77345433 -1.52810586]]\n","--------------------\n","Epoch ke: 2\n","Bobot MLP:\n","W1: [[-0.22200432  0.2782824   0.44719752  0.88608867]\n"," [ 0.30085681  0.16129761 -0.14268316 -1.83736066]\n"," [-0.75672197  1.13276119 -0.22766683 -0.75858159]\n"," [-2.60159677  1.30807812  2.12279204 -1.38519105]]\n","W2: [[ 0.76116463  1.15986188 -0.45593532]\n"," [-0.80853476  1.28091908  0.38420884]\n"," [-0.11850873 -0.08433371  0.86934998]\n"," [-0.79352435  0.95424131 -1.47219394]]\n","--------------------\n","Epoch ke: 3\n","Bobot MLP:\n","W1: [[-0.22581747  0.29913226  0.46365131  0.88378719]\n"," [ 0.25346971  0.07981427 -0.1489231  -1.87194606]\n"," [-0.74887833  1.17870837 -0.20506432 -0.75277259]\n"," [-2.60102526  1.34294389  2.14504634 -1.38675871]]\n","W2: [[ 1.0695538   1.22536673 -0.49283806]\n"," [-0.85043928  1.44985166  0.65121389]\n"," [-0.15537487  0.0839167   1.13005204]\n"," [-0.65223224  1.13646742 -1.41426494]]\n","--------------------\n","Epoch ke: 4\n","Bobot MLP:\n","W1: [[-0.23084671  0.32031513  0.48471382  0.87832041]\n"," [ 0.20580786 -0.00950314 -0.16626412 -1.90340833]\n"," [-0.74251133  1.22846307 -0.17357995 -0.75173501]\n"," [-2.60204295  1.38088355  2.17457591 -1.39380094]]\n","W2: [[ 1.37750511  1.29318792 -0.52966595]\n"," [-0.89555167  1.62392923  0.92054099]\n"," [-0.1937233   0.25323646  1.39212738]\n"," [-0.51322464  1.31970087 -1.35527794]]\n","--------------------\n","Epoch ke: 5\n","Bobot MLP:\n","W1: [[-0.23709752  0.3409159   0.50921185  0.8701286 ]\n"," [ 0.15807363 -0.10589421 -0.19399074 -1.93212685]\n"," [-0.73770416  1.28086135 -0.13462727 -0.7549008 ]\n"," [-2.60472793  1.42080345  2.21005292 -1.40572182]]\n","W2: [[ 1.68502463  1.36331308 -0.56643109]\n"," [-0.94361253  1.80353735  1.19203767]\n"," [-0.23410124  0.42442561  1.65601125]\n"," [-0.37522534  1.50357638 -1.29605533]]\n","--------------------\n","Epoch ke: 6\n","Bobot MLP:\n","W1: [[-0.24455908  0.36022641  0.53590646  0.85954609]\n"," [ 0.11048456 -0.2085842  -0.2312854  -1.95830839]\n"," [-0.73452769  1.33493961 -0.08972877 -0.76187461]\n"," [-2.60914535  1.46181981  2.25005665 -1.4221008 ]]\n","W2: [[ 1.99212287  1.4357122  -0.60314728]\n"," [-0.99430495  1.98896338  1.46547118]\n"," [-0.27682501  0.59817045  1.92196066]\n"," [-0.23713287  1.6877769  -1.23731016]]\n","--------------------\n","Epoch ke: 7\n","Bobot MLP:\n","W1: [[-0.25320366  0.37776624  0.56362988  0.84681814]\n"," [ 0.0632663  -0.3167311  -0.27730644 -1.9820191 ]\n"," [-0.73303727  1.38993759 -0.0403563  -0.77240707]\n"," [-2.61534457  1.50326376  2.29322653 -1.44266708]]\n","W2: [[ 2.29881495  1.51033712 -0.63982997]\n"," [-1.04730545  2.18040105  1.74056865]\n"," [-0.32200074  0.77503684  2.19006532]\n"," [-0.09797217  1.87201827 -1.17967229]]\n","--------------------\n","Epoch ke: 8\n","Bobot MLP:\n","W1: [[-0.26298654  0.39328635  0.59137323  0.83211955]\n"," [ 0.01664434 -0.42937777 -0.33124645 -2.00321035]\n"," [-0.7332696   1.44528429  0.01217755 -0.78636724]\n"," [-2.62335642  1.5446676   2.33836493 -1.46727237]]\n","W2: [[ 2.60512059  1.58712174 -0.67649612]\n"," [-1.10231284  2.37795045  2.01704856]\n"," [-0.36957537  0.95547654  2.46028022]\n"," [ 0.04314545  2.05603683 -1.12371064]]\n","--------------------\n","Epoch ke: 9\n","Bobot MLP:\n","W1: [[-0.27384669  0.40675848  0.61832512  0.81557349]\n"," [-0.02916491 -0.54542918 -0.39236415 -2.02173908]\n"," [-0.73524007  1.50057633  0.06677338 -0.80371623]\n"," [-2.63319096  1.58574077  2.38448653 -1.4958643 ]]\n","W2: [[ 2.91106398  1.66598306 -0.713164  ]\n"," [-1.15906016  2.58161468  2.2946431 ]\n"," [-0.41939545  1.13984121  2.73246593]\n"," [ 0.18705362  2.23957973 -1.06995043]]\n","--------------------\n","Epoch ke: 10\n","Bobot MLP:\n","W1: [[-0.28570795  0.41834833  0.64387427  0.79727062]\n"," [-0.07396311 -0.66367123 -0.45999029 -2.03738484]\n"," [-0.73894078  1.55555326  0.12255543 -0.82448146]\n"," [-2.64483587  1.62633969  2.43082589 -1.5284604 ]]\n","W2: [[ 3.21667329  1.74682306 -0.74985293]\n"," [-1.21731624  2.79129714  2.57311234]\n"," [-0.471258    1.32839854  3.00642626]\n"," [ 0.33455373  2.42239749 -1.01888516]]\n","--------------------\n","Accuracy: 0.6666666666666666\n"]}]},{"cell_type":"code","source":["def show_architecture(mlp):\n","    print(\"MLP Architecture:\")\n","    print(f\"Input layer: {mlp.input_size} neurons\")\n","    print(f\"Hidden layer: {mlp.hidden_size} neurons\")\n","    print(f\"Output layer: {mlp.output_size} neurons\")\n","show_architecture(mlp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqLwce8Rr4QK","executionInfo":{"status":"ok","timestamp":1684310691801,"user_tz":-420,"elapsed":334,"user":{"displayName":"20-055 WAHYU ARIL SAPUTRA","userId":"15073584488611319877"}},"outputId":"cbcf2052-ff04-4da2-b059-2f6e7371bff9"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Architecture:\n","Input layer: 4 neurons\n","Hidden layer: 4 neurons\n","Output layer: 3 neurons\n"]}]}]}